import os
from TTS.api import TTS

# âœ… Accept Coqui TOS to avoid prompt
os.environ["COQUI_TOS_AGREED"] = "1"

# âœ… Initialize the XTTS model from local path if already downloaded
model_path = "tts_models/multilingual/multi-dataset/xtts_v2"
tts = TTS(model_path)

# âœ… Input: Map language and gender to speaker reference WAVs
speaker_wavs = {
    "en_female": "Voice/en_female.wav",
    "en_male": "Voice/en_male.wav",
    "hi_female": "Voice/hi_female.wav",
    "hi_male": "Voice/hi_male.wav"
}

# âœ… User-defined text and settings
text = "Welcome to the multilingual speech synthesis demo."  # ðŸ‘ˆ You can change this
lang = "en"       # "en" for English, "hi" for Hindi
gender = "female" # "female" or "male"

# âœ… Create speaker key and locate reference file
speaker_key = f"{lang}_{gender}"
speaker_wav = speaker_wavs.get(speaker_key)

# âœ… Sanity check: ensure reference file exists
if not os.path.isfile(speaker_wav):
    raise FileNotFoundError(f"Reference WAV file not found: {speaker_wav}")

# âœ… Create output folder
output_dir = "output"
os.makedirs(output_dir, exist_ok=True)

# âœ… Output file name
output_path = os.path.join(output_dir, f"{speaker_key}_output.wav")

# âœ… Run XTTS inference and generate audio
tts.tts_to_file(
    text=text,
    speaker_wav=speaker_wav,
    language=lang,
    file_path=output_path
)

print(f"âœ… Synthesized audio saved to: {output_path}")
